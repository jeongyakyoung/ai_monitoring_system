import cv2
import random
from ultralytics import YOLO
import numpy as np
import datetime
import copy
import telegram
import asyncio
from collections import defaultdict
import threading
import os
import sys
from threading import Lock
import atexit
import time
import gc
import serial
import time
#from  gpiozero import OutputDevice ë¼ì¦ˆë² ë¦¬ íŒŒì´ìš©

# class WarningLight_raspberry:
#     def __new__(cls):
#         if not hasattr(cls, 'instance'):
#             cls.instance = super(WarningLight, cls).__new__(cls)
#             cls._initialized = False
#         return cls.instance
    
#     def __init__(self, pin_num=21):
#         if self.__class__._initialized:
#             return
#         self.relay = OutputDevice(pin_num, active_high=True, initial_value=False) ë¼ì¦ˆë² ë¦¬íŒŒì´ìš©
#         self.__class__._initialized = True
#         self._off_timer = None
        
#     def on(self, auto_off_seconds=30):
#         self.relay.on()
        
#         if self._off_timer and self._off_timer.is_alive():
#             self._off_timer.cancel()
        
#         self._off_timer = threading.Timer(auto_off_seconds, self.off)
#         self._off_timer.start()
    
#     def off(self):
#         if self._off_timer and self._off_timer.is_alive():
#             self._off_timer.cancel()
            
#         self._off_timer = None
#         self.relay.off()

class WarningLight:
    def __new__(cls, *args, **kwargs):
        if not hasattr(cls, 'instance'):
            cls.instance = super(WarningLight, cls).__new__(cls)
            cls._initialized = False
        return cls.instance
    
    def __init__(self, com_port='COM5'):
        if self.__class__._initialized:
            return
        ser = serial.Serial(com_port, 9600, timeout=1)
        self.relay = ser
        self.relay.write(bytes.fromhex('A0 01 00 A1')) # ì¼œì ¸ìˆìŒ ë„ê¸°
        self.__class__._initialized = True
        self._off_timer = None
        
    def on(self, auto_off_seconds=5):
        self.relay.write(bytes.fromhex('A0 01 01 A2'))
        
        if self._off_timer and self._off_timer.is_alive():
            self._off_timer.cancel()
        
        self._off_timer = threading.Timer(auto_off_seconds, self.off)
        self._off_timer.start()
    
    def off(self):
        if self._off_timer and self._off_timer.is_alive():
            self._off_timer.cancel()
            
        self._off_timer = None
        self.relay.write(bytes.fromhex('A0 01 00 A1'))

# Load the YOLO model
class Messenger:
    _instance = None
    _lock = Lock()
    
    def __new__(cls, *args, **kwargs):
        with cls._lock:
            if cls._instance is None:
                cls._instance = super(Messenger, cls).__new__(cls)
        return cls._instance
    
    def __init__(self) -> None:
        # ì²« ì´ˆê¸°í™” ì‹œì—ë§Œ ì‹¤í–‰
        if not hasattr(self, 'initialized'):
            self.token = None
            self.chat_id = None
            self.initialized = True
            atexit.register(self.cleanup_images)
            
    def set_telegram(self, token, chat_id):
        self.token = token # "7535814762:AAHmB72JRqiRcDxdyHrUoBtbuC573FhyXq0"
        self.chat_id = chat_id # "-4519677286"
        
    def send_photo(self, img_path):
        print("img_path", img_path)
        if not self.token or not self.chat_id:
            raise ValueError("Telegram token or chat_id is not set.")
        
        async def main():
            try:
                bot = telegram.Bot(self.token)
                with open(img_path, 'rb') as photo:
                    await bot.send_photo(chat_id=self.chat_id, photo=photo)
                print(f"ì´ë¯¸ì§€ ì „ì†¡ ì™„ë£Œ: {img_path}")
            except Exception as e:
                print(f"ì´ë¯¸ì§€ ì „ì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            finally:
                time.sleep(1)
                self.remove_file(img_path)
                
        try:    
            if sys.platform.startswith("win"):
                asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
            asyncio.run(main())
        except Exception as e:
            print(f"ë¹„ë™ê¸° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self.remove_file(img_path)
    
    def remove_file(self, img_path):
        max_attempts = 3
        for attempt in range(max_attempts):
            try:
                if os.path.exists(img_path):
                    os.remove(img_path)
                    print(f"íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {img_path}")
                    break
            except Exception as e:
                print(f"íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                if attempt < max_attempts - 1:
                    print(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨, ì¬ì‹œë„ ì¤‘... ë‚¨ì€ ì‹œë„ íšŸìˆ˜: {max_attempts - attempt - 1}")
                    time.sleep(0.2)
                else:
                    print(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨, ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ë„ë‹¬: {img_path}")
                    
                
    def cleanup_images(self):
        """í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ img í´ë”ì˜ falling ì´ë¯¸ì§€ë“¤ ì •ë¦¬"""
        try:
            if os.path.exists("img"):
                for file in os.listdir("img"):
                    if file.endswith(".jpg"):
                        file_path = os.path.join("img", file)
                        max_attempts = 3
                        for attempt in range(max_attempts):
                            try:
                                if os.path.exists(file_path):
                                    os.remove(file_path)
                                    print(f"Cleanup: ë‚¨ì€ ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ - {file}")
                                    break
                            except Exception as e:
                                print(f"Cleanup: íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ - {file}: {e}")
                                if attempt < max_attempts - 1:
                                    print(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨, ì¬ì‹œë„ ì¤‘... ë‚¨ì€ ì‹œë„ íšŸìˆ˜: {max_attempts - attempt - 1}")
                                    time.sleep(1.0)
                                else:
                                    print(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨, ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ë„ë‹¬: {file_path}")
                                    
        except Exception as e:
            print(f"Cleanup: ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {e}")
            
    def send_message(self, text):
        if not self.token or not self.chat_id:
            raise ValueError("Telegram token or chat_id is not set.")
        async def main():
            bot = telegram.Bot(self.token)
            await bot.send_message(chat_id=self.chat_id, text=text)
        
        if sys.platform.startswith("win"):
            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
        asyncio.run(main())
    
    def resource_path(self, relative_path):
        base_path = getattr(sys, "_MEIPASS", os.path.dirname(os.path.abspath(__file__)))
        return os.path.join(base_path, relative_path)
    
    def test_telegram_msg(self):
        today = datetime.datetime.now()
        timestamp = today.strftime('%Y%m%d_%H%M%S_%f')  # ë°€ë¦¬ì´ˆê¹Œì§€ í¬í•¨
        
        label = "Test telegram"
        test_img = np.zeros((480, 640, 3))
        test_img_h, test_img_w, _ = test_img.shape
        cv2.putText(test_img, label, (test_img_w//2, test_img_h//2), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        
        img_folder = self.resource_path("img")
        os.makedirs(img_folder, exist_ok=True)
        
        save_img_path = f'test_img_{timestamp}.jpg'
        result_path = os.path.join(img_folder, save_img_path)
        
        cv2.imwrite(result_path, test_img)
        
        self.send_photo(result_path)
            
class Detector:
    _instance = None
    
    def __new__(cls, conf, th, fps):
        if cls._instance is None:
            cls._instance = super(Detector, cls).__new__(cls)
            cls._instance.init_detector(conf, th, fps)  #  ì´ˆê¸°í™” ì‹¤í–‰
        return cls._instance
    
    def init_detector(self, conf, th, fps) -> None:
        self.telegram = Messenger()
        self.model = None
        self.cap = None
        self.save_img_path = None
        self.save_video_path = None
        
        self.model_conf = conf
        self.model_img_w = 640
        self.model_img_h = 640
        
        self.fps = fps
        self.original_th = th
        self.tracking_th = int(th * fps)
        
        self.font_scale = None
        self.font = None
        self.font_thickness = None
        
        self.origin_img = None
        
        self.track_history = defaultdict(lambda: [])
        self.continuous_count = defaultdict(int) # ì—°ì† ì¹´ìš´íŠ¸ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
        
        self.file_lock = threading.Lock()
        
        self.set_model()
        self.set_font()
        self.set_skeleton_point_bgr()
        
        # self._make_img_folder()
        
        self.out = None
        # self.set_save_video()
        
        self.join_parts = [
                            (0, 1), (1, 2), (1, 3), (2, 4), (3, 4),    # ì–¼êµ´ ì—°ê²°
                            (5, 6),                                     # ì–´ê¹¨ ì—°ê²°
                            (5, 7), (7, 9),                             # ì™¼íŒ”: ì–´ê¹¨, íŒ”ê¿ˆì¹˜, ì†ëª©
                            (6, 8), (8, 10),                            # ì˜¤ë¥¸íŒ”: ì–´ê¹¨, íŒ”ê¿ˆì¹˜, ì†ëª©
                            (11, 12),                                   # ì—‰ë©ì´ ì—°ê²°
                            (11, 13), (13, 15),                         # ì™¼ë‹¤ë¦¬: ì—‰ë©ì´, ë¬´ë¦, ë°œëª©
                            (12, 14), (14, 16),                         # ì˜¤ë¥¸ë‹¤ë¦¬: ì—‰ë©ì´, ë¬´ë¦, ë°œëª©
                            ('chest', 11), ('chest', 12),               # ê°€ìŠ´ì—ì„œ ì—‰ë©ì´ë¡œ
                            ('chest', 0)                                # ê°€ìŠ´ì—ì„œ ëª©ìœ¼ë¡œ
                            ]
        
        self.warning_light = WarningLight()
        
    def set_model(self, model_path="./yolo11n-pose_safety.pt"):
        try:
            if not os.path.exists(model_path):
                raise FileNotFoundError(f"ğŸš¨ ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")

            self.model = YOLO(model_path)

            if self.model is None:
                raise RuntimeError("ğŸš¨ YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: ëª¨ë¸ì´ None ìƒíƒœì…ë‹ˆë‹¤.")

            print("âœ… YOLO ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")

        except Exception as e:
            print(f"ğŸš¨ YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.model = None  # ğŸš¨ ëª¨ë¸ì´ None ìƒíƒœë¼ë©´ ìœ ì§€í•˜ì§€ ì•Šë„ë¡ ì„¤ì •
            raise RuntimeError(f"YOLO ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")  # âœ… ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ë˜ì§€ê¸°

    
    def adjust_tracking_threshold(self, actual_fps):
        self.tracking_th = int(self.original_th * actual_fps)
        
    def change_fps(self, fps):
        self.fps = fps
        
    def change_value(self, ai_model_conf, tracking_th):
        self.model_conf = ai_model_conf
        self.original_th = tracking_th
        self.tracking_th = int(tracking_th * self.fps)
        
    def resource_path(self, relative_path):
        base_path = getattr(sys, "_MEIPASS", os.path.dirname(os.path.abspath(__file__)))
        return os.path.join(base_path, relative_path)

    def set_model(self, model_kind="./yolo11n-pose_safety.pt"):
        # model_dir = './model'
        # os.makedirs(model_dir, exist_ok=True)
        # model_name = "yolo11n-pose.pt"
        # model_path = self.resource_path(os.path.join(model_dir, model_name))
        model_path = self.resource_path(model_kind)
        self.model = YOLO(model_path)
    
    def set_font(self):
        self.font_scale = 0.5
        self.font = cv2.FONT_HERSHEY_SIMPLEX
        self.font_thickness = 2
    
    def draw_falling_result(self, img, x1, y1, x2, y2):
        label = "Falling"
                    
        text_size, _ = cv2.getTextSize(label, self.font, self.font_scale, self.font_thickness)
        text_w, text_h = text_size
    
        # í…ìŠ¤íŠ¸ ë°°ê²½ ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
        cv2.rectangle(img, (x1, y1 - text_h - 10), (x1 + text_w, y1), (0, 0, 255), -1)

        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
        cv2.putText(img, label, (x1, y1 - 5), self.font, self.font_scale, (255, 255, 255), self.font_thickness)

        # ìœ„í—˜í•œ ì‚¬ëŒì— ëŒ€í•´ ë¹¨ê°„ìƒ‰ ë°”ìš´ë”© ë°•ìŠ¤ í‘œì‹œ
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)
    
    def draw_normal_result(self, img, x1, y1, x2, y2):
        label = "Normal"
        text_size, _ = cv2.getTextSize(label, self.font, self.font_scale, self.font_thickness)
        text_w, text_h = text_size
        # í…ìŠ¤íŠ¸ ë°°ê²½ ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
        cv2.rectangle(img, (x1, y1 - text_h - 10), (x1 + text_w, y1), (0, 255, 0), -1)

        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
        cv2.putText(img, label, (x1, y1 - 5), self.font, self.font_scale, (255, 255, 255), self.font_thickness)

        # ì •ìƒ ìƒíƒœì¼ ë•Œ ë…¹ìƒ‰ ë°”ìš´ë”© ë°•ìŠ¤ í‘œì‹œ
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
    
    def set_skeleton_point_bgr(self):
        self.nose_bgr = (255, 0, 0)
        self.left_pelvis_bgr = (0, 255, 0)
        self.right_pelvis_bgr = (0, 0, 255)
        self.left_knee_bgr = (255, 255, 0)
        self.right_knee_bgr = (0, 255, 255)
        
    def draw_skeleton(self, img, point_x, point_y, color):
        cv2.circle(img, (point_x, point_y), 5, color, -1, cv2.LINE_AA)
    
    def _change_fps_to_second(self, fps, th):
        result = int(fps * th)
        return result
    
    def tracker_update(self, frame, track_id, x1, y1, x2, y2, telegram_flag):
        track = self.track_history[track_id]
        track.append((x1, y1))
        
        # ì´ì „ ì¢Œí‘œì™€ ë¹„êµ
        if len(track) >= 2:
            prev_x, prev_y = track[-2]
            curr_x, curr_y = track[-1]
            
            if abs(curr_x - prev_x) < 30 and abs(curr_y - prev_y) < 30: # ì¢Œí‘œê°€ ë¹„ìŠ·í•œ ê²½ìš°
                self.continuous_count[track_id] += 1
            else:
                self.continuous_count[track_id] = 0
                
            if self.continuous_count[track_id] >= self.tracking_th:
                self.continuous_count[track_id] = 0
                del(self.track_history[track_id])
                img_path = self.save_falling_img(frame, x1, y1, x2, y2)
                full_img_path = self.save_full_img(self.origin_img)
                self.warning_light.on()
                
                if telegram_flag:
                    telegram_thread_crop = threading.Thread(target=self.telegram.send_photo, args=(img_path,), daemon=True)
                    telegram_thread_crop.start()
                    telegram_thread_full = threading.Thread(target=self.telegram.send_photo, args=(full_img_path,), daemon=True)
                    telegram_thread_full.start()
                    
        if len(track) > 30: # ìµœëŒ€ 30ê°œì˜ ì¢Œí‘œë§Œ ì €ì¥
            track.pop(0)
    
    def reset_tracking(self):
        """ğŸ”„ ì¼ì • ì£¼ê¸°ë§ˆë‹¤ íŠ¸ë˜ì»¤ ë°ì´í„° ì´ˆê¸°í™”"""
        print("ê°•ì œ íŠ¸ë˜ì»¤ ì´ˆê¸°í™”!")
        self.track_history.clear()
        self.continuous_count.clear()
        
    def predict(self, frame, telegram_flag=True, visualize_falg=True):
        if len(self.track_history) > 5000:
            print("Tracker Reset: YOLO ê°ì²´ ì¶”ì  ì´ˆê¸°í™”")
            results = self.model.track(frame, conf=self.model_conf, persist=True, tracker=None, verbose=False)
            self.reset_tracking()
            
        else:
            results = self.model.track(frame, conf=self.model_conf, persist=True, verbose=False)
            
        self.origin_img = copy.deepcopy(frame) #results[0].orig_img
        keypoints = results[0].keypoints
        boxes = results[0].boxes
        
        self.visualize_skeleton_bbox(boxes, keypoints, mode=visualize_falg)
        
        for (keypoint, box) in zip(keypoints, boxes):
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            human_width = x2-x1
            human_height = y2-y1
                
            nose_conf = keypoint.conf[0][0].to('cpu').numpy()
            nose = keypoint.xy[0][0].to('cpu').numpy()
            nose_x, nose_y = int(nose[0]), int(nose[1])
            
            
            left_pelvis_conf = keypoint.conf[0][11].to('cpu').numpy()
            left_pelvis = keypoint.xy[0][11].to('cpu').numpy() # ì™¼ìª½ ì–´ê¹¨
            left_pelvis_x, left_pelvis_y = int(left_pelvis[0]), int(left_pelvis[1])
            
            
            right_pelvis_conf = keypoint.conf[0][12].to('cpu').numpy()
            right_pelvis = keypoint.xy[0][12].to('cpu').numpy() # ì˜¤ë¥¸ìª½ ì–´ê¹¨
            right_pelvis_x, right_pelvis_y = int(right_pelvis[0]), int(right_pelvis[1])
            
            
            left_knee_conf = keypoint.conf[0][13].to('cpu').numpy()
            left_knee = keypoint.xy[0][13].to('cpu').numpy() # ì™¼ìª½ ë¬´ë¦
            left_knee_x, left_knee_y = int(left_knee[0]), int(left_knee[1])
            
            
            right_knee_conf = keypoint.conf[0][14].to('cpu').numpy()
            right_knee = keypoint.xy[0][14].to('cpu').numpy() # ì˜¤ë¥¸ìª½ ë¬´ë¦
            right_knee_x, right_knee_y = int(right_knee[0]), int(right_knee[1])
            
            left_shoulder_conf = keypoint.conf[0][5].to('cpu').numpy()
            left_shoulder = keypoint.xy[0][5].to('cpu').numpy()
            left_shoulder_x, left_shoulder_y = int(left_shoulder[0]), int(left_shoulder[1])
            
            right_shoulder_conf = keypoint.conf[0][6].to('cpu').numpy()
            right_shoulder = keypoint.xy[0][6].to('cpu').numpy()
            right_shoulder_x, right_shoulder_y = int(right_shoulder[0]), int(right_shoulder[1])
            
            left_wrist_conf = keypoint.conf[0][9].to('cpu').numpy()
            left_wrist = keypoint.xy[0][9].to('cpu').numpy()
            left_wrist_x, left_wrist_y = int(left_wrist[0]), int(left_wrist[1])
            
            right_wrist_conf = keypoint.conf[0][10].to('cpu').numpy()
            right_wrist = keypoint.xy[0][10].to('cpu').numpy()
            right_wrist_x, right_wrist_y = int(right_wrist[0]), int(right_wrist[1])
            
            if (nose_conf >= 0.5 and left_pelvis_conf >= 0.5 and right_pelvis_conf >= 0.5 and left_knee_conf >= 0.5 and right_knee_conf >= 0.5
                and left_shoulder_conf >= 0.5 and right_shoulder_conf >= 0.5 and left_wrist_conf >= 0.5 and right_wrist_conf>=0.5):
                # self.draw_skeleton(self.origin_img, nose_x, nose_y, self.nose_bgr)
                # self.draw_skeleton(self.origin_img, left_pelvis_x, left_pelvis_y, self.left_pelvis_bgr)
                # self.draw_skeleton(self.origin_img, left_knee_x, left_knee_y, self.left_knee_bgr)
                # self.draw_skeleton(self.origin_img, right_pelvis_x, right_pelvis_y, self.right_pelvis_bgr)
                # self.draw_skeleton(self.origin_img, right_knee_x, right_knee_y, self.right_knee_bgr)

                if (left_pelvis_y >= left_knee_y or right_pelvis_y >= right_knee_y or left_pelvis_y <= nose_y or right_pelvis_y <= nose_y or
                    left_shoulder_y <= nose_y or right_shoulder_y <= nose_y or left_wrist_y >= left_knee_y or right_wrist_y >= right_knee_y):
                    if box.id is not None:
                        track_id = box.id[0].int().cpu().tolist()
                        self.tracker_update(frame, track_id, x1, y1, x2, y2, telegram_flag)
                    self.draw_falling_result(self.origin_img, x1, y1, x2, y2)
                    
                else:
                    self.draw_normal_result(self.origin_img, x1, y1, x2, y2)
                    
            elif human_width >= human_height:
                if box.id is not None:
                    track_id = box.id[0].int().cpu().tolist()
                    self.tracker_update(frame, track_id, x1, y1, x2, y2, telegram_flag)
                self.draw_falling_result(self.origin_img, x1, y1, x2, y2)
                
            else:
                self.draw_normal_result(self.origin_img, x1, y1, x2, y2)
        
        gc.collect()
        
        return self.origin_img
    
    def visualize_skeleton_bbox(self, boxes, keypoints, mode=False):
        boxes = boxes.xyxy.cpu().numpy()
        if mode:
            for box, keypoint_set in zip(boxes, keypoints):
                # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ
                x1, y1, x2, y2 = map(int, box)

                # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                # cv2.rectangle(self.origin_img, (x1, y1), (x2, y2), (0, 255, 0), 2)
                points = []
                
                for coord, conf in zip(keypoint_set.xy[0], keypoint_set.conf[0]):
                    x, y = map(int, coord)
                    if conf >= self.model_conf:
                        points.append((x, y))
                        cv2.circle(self.origin_img, (x, y), 5, (0, 0, 255), -1)
                    else:
                        points.append(None)
                        
                if points[5] is not None and points[6] is not None:
                    chest_x = (points[5][0] + points[6][0]) // 2
                    chest_y = (points[5][1] + points[6][1]) // 2
                    chest_point = (chest_x, chest_y)
                    points.append(chest_point)  # ê°€ìŠ´ ì¢Œí‘œ ì¶”ê°€
                    cv2.circle(self.origin_img, chest_point, 5, (255, 0, 0), -1)  # íŒŒë€ìƒ‰ìœ¼ë¡œ ê°€ìŠ´ í‘œì‹œ
                else:
                    chest_point = None
                    points.append(None)

                # ê´€ì ˆ ì—°ê²° ê·¸ë¦¬ê¸°
                for start, end in self.join_parts:
                    # ê°€ìŠ´(chest)ì€ ë”°ë¡œ ì²˜ë¦¬
                    if start == 'chest':
                        start_point = chest_point
                    else:
                        start_point = points[start]

                    if end == 'chest':
                        end_point = chest_point
                    else:
                        end_point = points[end]

                    if start_point is not None and end_point is not None:
                        cv2.line(self.origin_img, start_point, end_point, (255, 0, 0), 2)
                        
    def _make_img_folder(self):
        os.makedirs('img', exist_ok=True)
            
    def save_falling_img(self, img, x1, y1, x2, y2):
        with self.file_lock:  # Lockì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ ì ‘ê·¼ ë™ê¸°í™”
            today = datetime.datetime.now()
            timestamp = today.strftime('%Y%m%d_%H%M%S_%f')  # ë°€ë¦¬ì´ˆê¹Œì§€ í¬í•¨
            
            crop_img = img[y1:y2, x1:x2]
            
            img_folder = self.resource_path("img")
            
            os.makedirs(img_folder, exist_ok=True)
            
            save_img_path = f'crop_img_{timestamp}.jpg'
          
            result_path = os.path.join(img_folder, save_img_path)
            
            cv2.imwrite(result_path, crop_img)
            return result_path

    def save_full_img(self, img):
        with self.file_lock:  # Lockì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ ì ‘ê·¼ ë™ê¸°í™”
            today = datetime.datetime.now()
            timestamp = today.strftime('%Y%m%d_%H%M%S_%f')  # ë°€ë¦¬ì´ˆê¹Œì§€ í¬í•¨
            
            img_folder = self.resource_path("img")
            
            os.makedirs(img_folder, exist_ok=True)
            
            save_img_path = f'full_img_{timestamp}.jpg'
                
            result_path = os.path.join(img_folder, save_img_path)
            
            cv2.imwrite(result_path, img)
            return result_path
        
    def set_save_video(self):
        fourcc = cv2.VideoWriter_fourcc(*'DIVX')
        fps = self.cap.get(cv2.CAP_PROP_FPS)
        # self.out = cv2.VideoWriter('output.avi', fourcc, fps, (self.model_img_w, self.model_img_h))
        
    def model_run(self, frame, telegram_flag, visualize_flag):
        resize_frame = cv2.resize(frame, dsize=(self.model_img_w, self.model_img_h), interpolation=cv2.INTER_LINEAR)
        result_img = self.predict(resize_frame, telegram_flag, visualize_flag)
        
        gc.collect()
        
        return result_img
    
    def run(self):
        count = 0
        while self.cap.isOpened():
            # Read a frame from the video
            success, frame = self.cap.read()
            count += 1
            if count % 5 != 0:
                continue
            if success:
                resize_frame = cv2.resize(frame, dsize=(self.model_img_w, self.model_img_h), interpolation=cv2.INTER_LINEAR)
                result_img = self.predict(resize_frame)
                cv2.imshow('result', result_img)
                # self.out.write(result_img)
                
            if cv2.waitKey(1) & 0xFF == ord("q"):
                break
            
        self.cap.release()
        self.out.release()
        cv2.destroyAllWindows()
        
if __name__ == "__main__":
    detector = Detector()
    detector.run()