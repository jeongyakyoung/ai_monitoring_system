import os
from PyQt5.QtWidgets import *
from PyQt5 import uic
from PyQt5.QtCore import QDate, QObject, Qt, QThread
from PyQt5.QtGui import QImage, QPixmap, QFontDatabase, QFont, QCursor, QPainter, QColor
from PyQt5.QtCore import pyqtSignal as Signal, pyqtSlot as Slot
import sys
from PyQt5.QtWidgets import QWidget
import cv2
from controller import Detector, Messenger, WarningLight
from setting import FileController
from PyQt5.QtCore import QFile, QTextStream, pyqtSignal
from functools import partial
import time
import gc
import subprocess

os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = (
    "rtsp_transport;tcp|"        # UDP ÎåÄÏã† TCPÎ°ú Ï†ÑÏÜ°(Ìå®ÌÇ∑ÏÜêÏã§ Ï§ÑÏûÑ)
    "fflags;nobuffer|"           # Î≤ÑÌçº ÏµúÏÜåÌôî
    "flags;low_delay|"           # Ï†ÄÏßÄÏó∞
    "probesize;32|"              # Î∂ÑÏÑù ÏµúÏÜåÌôî
    "analyzeduration;0|"         # Î∂ÑÏÑù ÏµúÏÜåÌôî
    "max_delay;0|"               # ÏµúÎåÄ ÏßÄÏó∞ 0
    "stimeout;2000000"           # ÏÜåÏºì ÌÉÄÏûÑÏïÑÏõÉ 2Ï¥à(Œºs Îã®ÏúÑ)
)

def resource_path(relative_path):
    base_path = getattr(sys, "_MEIPASS", os.path.dirname(os.path.abspath(__file__)))
    return os.path.join(base_path, relative_path)

form = resource_path('main.ui')
form_class = uic.loadUiType(form)[0]

form_telegram = resource_path('telegram.ui')
form_telegram_window = uic.loadUiType(form_telegram)[0]

form_model = resource_path('model_conf.ui')
form_model_window = uic.loadUiType(form_model)[0]

form_port = resource_path('relay_port.ui')
form_port_window = uic.loadUiType(form_port)[0]

import subprocess
import numpy as np
import cv2
import time
import gc

from PyQt5.QtCore import QThread, pyqtSignal, Qt
from PyQt5.QtGui import QImage, QPixmap, QColor, QPainter

import subprocess
import numpy as np
import cv2
import time
import gc

from PyQt5.QtCore import QThread, pyqtSignal, Qt
from PyQt5.QtGui import QImage, QPixmap, QColor, QPainter

import subprocess
import numpy as np
import cv2
import time
import gc

from PyQt5.QtCore import QThread, pyqtSignal, Qt
from PyQt5.QtGui import QImage, QPixmap, QColor, QPainter

import subprocess
import numpy as np
import cv2
import time
import gc
from threading import Thread
from queue import Queue, Empty

from PyQt5.QtCore import QThread, pyqtSignal, Qt
from PyQt5.QtGui import QImage, QPixmap, QColor, QPainter


# ÎùºÏ¶àÎ≤†Î¶¨ÌååÏù¥Ïö© #
# class CameraThread(QThread):
#     frame_signal = pyqtSignal(QPixmap, bool)
#     error_signal = pyqtSignal(str)

#     def __init__(self, port, ai_conf, tr_th, messenger):
#         super().__init__()

#         self.rtsp_url = "rtsp://admin:Cctv8324%21@192.168.1.101:554/trackID=1" # ÎùºÏ¶àÎ≤†Î¶¨ÌååÏù¥Ïö©
#         self.width = 640
#         self.height = 360
#         self.frame_size = self.width * self.height * 3

#         self.fps = 30
#         self.running = False
#         self.frame_queue = Queue(maxsize=1)

#         self.telegram_flag = True
#         self.skeleton_visualize_flag = True
#         self.messenger = messenger

#         try:
#             self.model = Detector(ai_conf, tr_th, self.fps)
#             if self.model.model is None:
#                 raise RuntimeError("YOLO Î™®Îç∏ Î°úÎìú Ïã§Ìå®")
#         except Exception as e:
#             self.error_signal.emit(f"AI Î™®Îç∏ Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e}")
#             self.model = None
#             return

#     def start_frame_reader(self):
#         def reader_loop():
#             cmd = [
#                 "ffmpeg",
#                 "-rtsp_transport", "tcp",
#                 "-fflags", "nobuffer",
#                 "-flags", "low_delay",
#                 "-an",
#                 "-i", self.rtsp_url,
#                 "-vf", "scale=640:360",                # Ìï¥ÏÉÅÎèÑ Ï∂ïÏÜå Ï∂îÍ∞Ä
#                 "-f", "image2pipe",
#                 "-pix_fmt", "bgr24",
#                 "-vcodec", "rawvideo",
#                 "-"
#             ]
#             try:
#                 pipe = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL, bufsize=10**8)
#                 while self.running:
#                     raw_frame = pipe.stdout.read(self.frame_size)
#                     if len(raw_frame) != self.frame_size:
#                         continue
#                     if self.frame_queue.full():
#                         try:
#                             self.frame_queue.get_nowait()  # Ïù¥Ï†Ñ ÌîÑÎ†àÏûÑ Ï†úÍ±∞
#                         except:
#                             pass
#                     self.frame_queue.put_nowait(raw_frame)
#             except Exception as e:
#                 self.error_signal.emit(f"ÌîÑÎ†àÏûÑ ÏàòÏã† Ïò§Î•ò: {e}")

#         Thread(target=reader_loop, daemon=True).start()

#     def run(self):
#         if self.model is None or self.model.model is None:
#             return

#         self.running = True
#         self.start_frame_reader() #ÎùºÏ¶àÎ≤†Î¶¨ÌååÏù¥Ïö©
#         frame_count = 0

#         while self.running:
#             try:
#                 raw_frame = self.frame_queue.get(timeout=2)
#                 frame = np.frombuffer(raw_frame, np.uint8).reshape((self.height, self.width, 3))

#                 start_time = time.time()

#                 result_img = self.model.model_run(frame, self.telegram_flag, self.skeleton_visualize_flag)

#                 resized = cv2.resize(result_img, (400, 300))
#                 rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
#                 h, w, ch = rgb.shape
#                 image = QImage(rgb.data, w, h, ch * w, QImage.Format_RGB888)
#                 pixmap = QPixmap.fromImage(image)

#                 fps_actual = 1.0 / (time.time() - start_time + 1e-6)
#                 self.model.adjust_tracking_threshold(fps_actual)

#                 self.frame_signal.emit(pixmap, True)

#                 frame_count += 1
#                 if frame_count >= 5000:
#                     self.model.reset_tracking()
#                     frame_count = 0
#                     time.sleep(1)

#                 gc.collect()

#             except Empty:
#                 self.send_black_frame()
#             except Exception as e:
#                 print(f"[Ïπ¥Î©îÎùº Ï≤òÎ¶¨ Ïò§Î•ò] {e}")
#                 self.send_black_frame()
#                 time.sleep(1)

#     def send_black_frame(self):
#         black = QImage(400, 300, QImage.Format_RGB888)
#         black.fill(QColor('black'))
#         painter = QPainter(black)
#         painter.setPen(QColor('white'))
#         painter.drawText(black.rect(), Qt.AlignCenter, "Ïπ¥Î©îÎùº Ïó∞Í≤∞ Ïã§Ìå®")
#         painter.end()
#         self.frame_signal.emit(QPixmap.fromImage(black), False)

#     def stop(self):
#         self.running = False
#         self.wait()


# ÏúàÎèÑÏö∞ Ïö© #
class CameraThread(QThread):
    frame_signal = pyqtSignal(QPixmap, bool)
    error_signal = pyqtSignal(str)

    def __init__(self, port, ai_conf, tr_th, messenger):
        super().__init__()
        url = "rtsp://admin:Cctv8324%21@192.168.1.101:554/trackID=1"
        
        self.port = port # url # IDIS Ïπ¥Î©îÎùº ÏòàÏãú: "rtsp://admin:1234@192.168.0.101:554/trackID=2"
        self.running = False
        self.cap = None
        self.fps = 30
        self.frame_start_time = None
        
        self.telegram_flag = True
        self.skeleton_visualize_flag = True
        self.model = Detector(ai_conf, tr_th, self.fps)
        
        self.messenger = messenger
        
        try:
            self.model = Detector(ai_conf, tr_th, self.fps)
            
            # ‚úÖ Î™®Îç∏Ïù¥ NoneÏù¥Î©¥ Ïã§Ìñâ Ï§ëÏßÄ
            if self.model.model is None:
                raise RuntimeError("üö® AI Î™®Îç∏ Ï¥àÍ∏∞Ìôî Ïã§Ìå®! YOLO Î™®Îç∏Ïù¥ Î°úÎìúÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.")
            
        except Exception as e:
            print(f"üö® AI Î™®Îç∏ Ï¥àÍ∏∞Ìôî Ïò§Î•ò: {e}")
            self.error_signal.emit(f"AI Î™®Îç∏ Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e}")
            self.model = None
            return  # ‚úÖ Ï¥àÍ∏∞Ìôî Ïã§Ìå® Ïãú Ïã§Ìñâ Ï§ëÎã®
    
    def run(self):
        if self.model is None or self.model.model is None:
            print("üö® YOLO Î™®Îç∏Ïù¥ Î°úÎìúÎêòÏßÄ ÏïäÏùå. Ïπ¥Î©îÎùº Ïã§Ìñâ Ï§ëÎã®.")
            return

        # --- Ï∫°Ï≤ò Ïò§Ìîà ---
        self.cap = cv2.VideoCapture(self.port, cv2.CAP_FFMPEG)
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

        def reopen():
            # Ïû¨Ïó∞Í≤∞ Ìó¨Ìçº
            try:
                if self.cap:
                    self.cap.release()
            except: pass
            time.sleep(0.2)
            self.cap = cv2.VideoCapture(self.port, cv2.CAP_FFMPEG)
            self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

        # ÏµúÏ¥à ÌîÑÎ†àÏûÑ ÌôïÏù∏
        for _ in range(8):  # ÏãúÏûë Ïãú Î≤ÑÌçº ÎπÑÏö∞Í∏∞
            self.cap.grab()
        ok, frame = self.cap.retrieve()
        if not ok:
            self.send_black_frame()
            return

        self.running = True
        frame_count = 0
        consecutive_fail = 0

        # Ï∂îÎ°† Ïä§ÌÇµ(ÏßÄÏó∞ Î∞©ÏßÄ) ‚Äî ÌïÑÏöî Ïãú 2~3ÏúºÎ°ú Ïò¨Î¶¨ÏÑ∏Ïöî
        INFER_EVERY = 2

        while self.running:
            try:
                loop_start = time.time()

                # --- Ïò§ÎûòÎêú ÌîÑÎ†àÏûÑ Î≤ÑÎ¶¨Í≥† ÏµúÏã†Îßå ÎîîÏΩîÎî© ---
                for _ in range(5):  # ÏÉÅÌô©Ïóê Îî∞Îùº 3~8 Ï°∞Ï†à
                    self.cap.grab()
                ok, frame = self.cap.retrieve()
                if not ok or frame is None:
                    consecutive_fail += 1
                    if consecutive_fail >= 10:
                        # ÎîîÏΩîÎî© ÏóêÎü¨Í∞Ä Î∞òÎ≥µÎêòÎ©¥ Ïû¨Ïó∞Í≤∞
                        reopen()
                        consecutive_fail = 0
                    self.send_black_frame()
                    continue
                else:
                    consecutive_fail = 0

                # --- FPS Î≥ÄÍ≤Ω Í∞êÏßÄ Ïãú Î™®Îç∏Ïóê Ï†ÑÎã¨(ÏÑ†ÌÉù) ---
                fps_prop = self.cap.get(cv2.CAP_PROP_FPS) or 0
                if fps_prop > 0:
                    self.model.change_fps(fps_prop)

                # --- Ï∂îÎ°† Ïä§ÌÇµÏúºÎ°ú ÏßÄÏó∞ ÏñµÏ†ú ---
                if frame_count % INFER_EVERY == 0:
                    try:
                        result_img = self.model.model_run(frame, self.telegram_flag, self.skeleton_visualize_flag)
                    except Exception as e:
                        print(f"AI Î™®Îç∏ Ïã§Ìñâ Ïò§Î•ò: {e}")
                        result_img = frame
                    last_result = result_img
                else:
                    # ÏßÅÏ†Ñ Í≤∞Í≥º Ïû¨ÏÇ¨Ïö©
                    result_img = last_result if 'last_result' in locals() else frame

                # --- ÎîîÏä§ÌîåÎ†àÏù¥ Î≥ÄÌôò ---
                resized_frame = cv2.resize(result_img, (640, 360),interpolation=cv2.INTER_AREA)
                rgb_frame = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)
                h, w, ch = rgb_frame.shape
                qt_image = QImage(rgb_frame.data, w, h, ch * w, QImage.Format_RGB888)
                pixmap = QPixmap.fromImage(qt_image)
                self.frame_signal.emit(pixmap, True)

                # --- Ïã§Ï†ú Ï≤òÎ¶¨ FPSÎ°ú Ìä∏ÎûòÌÇπ ÏûÑÍ≥ÑÍ∞í Î≥¥Ï†ï ---
                proc_time = time.time() - loop_start
                actual_fps = 1.0 / proc_time if proc_time > 0 else fps_prop
                self.model.adjust_tracking_threshold(actual_fps)

                # --- Ï£ºÍ∏∞Ï†Å Ìä∏ÎûòÌÇπ ÌûàÏä§ÌÜ†Î¶¨ Î¶¨ÏÖã(Ïä¨Î¶Ω Í∏àÏßÄ!) ---
                frame_count += 1
                if frame_count >= 5000:
                    self.model.reset_tracking()
                    frame_count = 0

                gc.collect()

            except Exception as e:
                print(f"Ïπ¥Î©îÎùº Ïä§Î†àÎìú Ïã§Ìñâ Ïò§Î•ò: {e}")
                self.send_black_frame()
                time.sleep(0.1)  # ÏßßÍ≤åÎßå

        # Ï¢ÖÎ£å
        try:
            self.cap.release()
        except: pass
    
    # def run(self):
    #     if self.model is None or self.model.model is None:
    #         print("üö® YOLO Î™®Îç∏Ïù¥ Î°úÎìúÎêòÏßÄ ÏïäÏùå. Ïπ¥Î©îÎùº Ïã§Ìñâ Ï§ëÎã®.")
    #         return
    #     self.cap = cv2.VideoCapture(self.port, cv2.CAP_FFMPEG)
    #     self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
    #     # self.cap = cv2.VideoCapture(self.port, cv2.CAP_GSTREAMER) # GSTREAMERÎäî ÎùºÏ¶àÎ≤†Î¶¨ÌååÏù¥Ïö©
    #     # self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        
    #     for _ in range(5):
    #         self.cap.grab()
    #     ok, frame = self.cap.retrieve()

    #     if not ok:
    #         # If the camera is not available, send a black frame
    #         self.send_black_frame()
    #         return

    #     self.running = True
    #     frame_count = 0
        
    #     while self.running:
    #         try:
    #             self.frame_start_time = time.time()
                
    #             ret, frame = self.cap.read()
    #             if not ret:
    #                 self.send_black_frame()
    #                 break
                
    #             fps = self.cap.get(cv2.CAP_PROP_FPS)
    #             self.model.change_fps(fps)
    #             try:
    #                 if self.model and hasattr(self.model, 'model_run'):
    #                     result_img = self.model.model_run(frame, self.telegram_flag, self.skeleton_visualize_flag)
    #                 else:
    #                     print("AI Î™®Îç∏Ïù¥ Ï¥àÍ∏∞ÌôîÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.")
    #                     result_img = frame
    #             except Exception as e:
    #                 print(f"AI Î™®Îç∏ Ïã§Ìñâ Ïò§Î•ò Î∞úÏÉù: {(e)}")
    #                 result_img = frame
                    
    #             gc.collect()
                
    #             resized_frame = cv2.resize(result_img, (400, 300)) # ÏõêÎûò ÏΩîÎìúÎäî result_img
    #             rgb_frame = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)
    #             h, w, ch = rgb_frame.shape
    #             bytes_per_line = ch * w
    #             qt_image = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format_RGB888)
    #             pixmap = QPixmap.fromImage(qt_image)
                
    #             processing_time = time.time() - self.frame_start_time
    #             actual_fps = 1.0 / processing_time if processing_time > 0 else fps
            
    #             self.model.adjust_tracking_threshold(actual_fps)
                
    #             self.frame_signal.emit(pixmap, True)
                
    #             frame_count += 1
    #             if frame_count >= 5000:
    #                 self.model.reset_tracking()
    #                 frame_count = 0
                    
                    
    #         except Exception as e:
    #             print(f"Ïπ¥Î©îÎùº Ïä§Î†àÎìú Ïã§Ìñâ Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}")
    #             self.send_black_frame()
    #             time.sleep(1)
                
    #     self.cap.release()
        
    def send_black_frame(self):
        """Send a black frame with a 'Camera Unavailable' message."""
        black_image = QImage(400, 300, QImage.Format_RGB888)
        black_image.fill(QColor('black'))
        painter = QPainter(black_image)
        painter.setPen(QColor('white'))
        painter.setFont(painter.font())
        painter.drawText(black_image.rect(), Qt.AlignCenter, "Ïπ¥Î©îÎùº Ïó∞Í≤∞ Ïã§Ìå®")
        painter.end()
        black_pixmap = QPixmap.fromImage(black_image)
        self.frame_signal.emit(black_pixmap, False)
        
    def stop(self):
        self.running = False
        self.wait()
#--------------------------------------------------------------------------------------------#

    # def run(self): # ÎèôÏòÅÏÉÅÌååÏùº Ïã§ÌñâÏãú(Îç∞Î™® Î≤ÑÏ†Ñ)
    #     self.cap = cv2.VideoCapture('./soruce/falling_6.mp4')
        
    #     while self.cap.isOpened():
    #         ret ,frame = self.cap.read()
    #         if not ret:
    #             self.stop()
    #         else:
    #             last_frame = self.cvimage_to_label(frame)
    #             self.frame_signal.emit(last_frame)

    def change_telegram_func(self, flag):
        self.telegram_flag = flag
    
    def change_skeleton_visualize_func(self, flag):
        self.skeleton_visualize_flag = flag
        
class TelegramwindowClass(QDialog, QWidget, form_telegram_window): 
    def __init__(self):
        super(TelegramwindowClass, self).__init__()
        self.initUi()
        self.setting = FileController()
        self.json_data = self.setting.load_json()
        self.set_telegram_api_label()
        self.set_telegram_id_label()
        self.save_btn.clicked.connect(self.save_value)
    
    def initUi(self):
        self.setupUi(self)
        self.setWindowTitle("ÌÖîÎ†àÍ∑∏Îû® Ï†ïÎ≥¥ Îì±Î°ù")
    
    def get_telegram_token(self):
        self.json_data = self.setting.load_json()
        return self.json_data['telegram_api']
    
    def get_telegram_bot_id(self):
        self.json_data = self.setting.load_json()
        return self.json_data['telegram_bot_id']
    
    def set_telegram_api_label(self):
        api = self.json_data['telegram_api']
        if api is None or api == "":
            self.telegram_api_label.setText("")
        else:
            self.telegram_api_label.setText(str(api))
        
    def set_telegram_id_label(self):
        id = self.json_data['telegram_bot_id']
        if id is None or id == "":
            self.telegram_id_label.setText("")
        else:
            self.telegram_id_label.setText(str(id))
        
    # def enroll_telegram_info(self):
    #     self.messenger.set_telegram(self.telegram_api_label.text(), self.telegram_id_label.text())
        
    def get_telegram_api_label(self):
        return self.telegram_api_label.text()
    
    def get_telegram_id_label(self):
        return self.telegram_id_label.text()

    def save_telegram_id_label(self):
        id = self.telegram_id_label.text()
        self.setting.revise_str_json('telegram_bot_id', str(id))
        
    def save_telegram_api_label(self):
        api = self.telegram_api_label.text()
        self.setting.revise_str_json('telegram_api', str(api))

    def save_value(self):
        self.save_telegram_api_label()
        self.save_telegram_id_label()
        self.save_popup()
        
    def save_popup(self):
        QMessageBox.information(self, "OK", "Ï†ÄÏû• ÏôÑÎ£å")
        
    def open(self):
        self.exec_()
        
class ModelwindowClass(QDialog, QWidget, form_model_window): 
    def __init__(self):
        super(ModelwindowClass, self).__init__()
        self.initUi()
        self.setting = FileController()
        self.json_data = self.setting.load_json()
        self.set_model_conf()
        self.set_tracking_th()
        self.save_btn.clicked.connect(self.save_value)
        
        self.ai_conf = 0
        self.tr_th = 0
        
    def initUi(self):
        self.setupUi(self)
        self.setWindowTitle("Î™®Îç∏ Ï∂îÎ°† ÏûÑÍ≥ÑÍ∞í Î≥ÄÍ≤Ω")
        
    def save_model_conf(self):
        self.ai_conf = float(self.model_conf_label.text())
        self.setting.revise_str_json('ai_model_conf', float(self.ai_conf))
        
    def set_model_conf(self):
        self.ai_conf = self.json_data['ai_model_conf']
        self.model_conf_label.setText(str(self.ai_conf))
    
    def save_tracking_th(self):
        self.tr_th = float(self.tracking_th.text())
        self.setting.revise_str_json('tracking_th', int(self.tr_th))
        
    def set_tracking_th(self):
        self.tr_th = self.json_data['tracking_th']
        self.tracking_th.setText(str(self.tr_th))
        
    def save_popup(self):
        QMessageBox.information(self, "OK", "Ï†ÄÏû• ÏôÑÎ£å")
    
    def save_value(self):
        self.save_model_conf()
        self.save_tracking_th()
        self.save_popup()
    
    def get_ai_conf(self):
        return self.ai_conf
    
    def get_tracking_threshold(self):
        return self.tr_th
    
    def open(self):
        self.exec_()

class RelayPortwindowClass(QDialog, QWidget, form_port_window): 
    def __init__(self):
        super(RelayPortwindowClass, self).__init__()
        self.initUi()

        self.port_num = ""

        self.save_btn.clicked.connect(self.save_port_num)
        self.setting = FileController()
        self.json_data = self.setting.load_json()

        self.set_relay_module_port_num()

    def initUi(self):
        self.setupUi(self)
        self.setWindowTitle("Î¶¥Î†àÏù¥ Î™®Îìà Ìè¨Ìä∏ Î≤àÌò∏ Î≥ÄÍ≤Ω")
    
    def set_relay_module_port_num(self):
        self.port_num = self.json_data['relay_module_port']
        self.port_value.setText(self.port_num) # Í∞í ÏÑ§Ï†ï

    def save_popup(self):
        QMessageBox.information(self, "OK", "Ìè¨Ìä∏ Î≥ÄÍ≤Ω ÏôÑÎ£å")

    def save_port_num(self):
        self.port_num =  self.port_value.text()
        self.setting.revise_str_json('relay_module_port', str(self.port_num).upper())
        self.save_popup()
        #self.port_value.setText(text) # Í∞í ÏÑ§Ï†ï

    def get_port_num(self):
        return self.port_num
    
    def open(self):
        self.exec_()

class CameraPreview(QWidget):
    closed = pyqtSignal(str)
    
    def __init__(self, camera_name, parent=None):
        super().__init__(parent)
        self.w = 1280
        self.h = 720
        self.camera_name = camera_name
        
        self.setWindowTitle(f"{camera_name} - ÌôïÎåÄ Î≥¥Í∏∞")
        self.setGeometry(100, 100, self.w, self.h)  # ÌôïÎåÄ Ï∞ΩÏùò Í∏∞Î≥∏ ÌÅ¨Í∏∞

        self.layout = QVBoxLayout(self)
        self.video_label = QLabel(self)
        self.video_label.setAlignment(Qt.AlignCenter)
        self.video_label.setStyleSheet("border: 1px solid black; background-color: #000;")
        self.layout.addWidget(self.video_label)

    def update_frame(self, pixmap):
        """Update the frame in the preview window."""
        self.video_label.setPixmap(pixmap.scaled(self.w, self.h, Qt.KeepAspectRatio, Qt.SmoothTransformation))
    
    def closeEvent(self, event):
        """Signal when the preview window is closed."""
        self.closed.emit(self.camera_name)
        super().closeEvent(event)
                
class WindowClass(QMainWindow, form_class):
    def __init__(self):
        super(WindowClass, self).__init__()
        self.setupUi(self)
        self.load_stylesheet()
        self.set_cursor()
        self.setWindowTitle("AIÍ∏∞Î∞ò ÏúÑÌóòÍ∞êÏßÄ Î™®ÎãàÌÑ∞ÎßÅ ÏãúÏä§ÌÖú")

        self.setting = FileController()
        self.json_data = self.setting.load_json()
        
        self.camera_threads = {}
        self.video_labels = {}
        
        self.active_thread = None
        
        self.telegram_winodw_class = TelegramwindowClass()
        self.telegram_enroll_btn.clicked.connect(self.open_telegram_info_dialog)
        
        self.model_window_class = ModelwindowClass()
        self.ai_model_conf_btn.clicked.connect(self.open_model_conf_dialog)
        
        self.relay_port_window_class = RelayPortwindowClass()

        self.messenger = Messenger()
        self.api_token = self.telegram_winodw_class.get_telegram_api_label()
        self.chat_id = self.telegram_winodw_class.get_telegram_id_label()
        
        self.change_relay_port_btn.clicked.connect(self.open_relay_port_dialog)

        self.warning_light = WarningLight(self.json_data['relay_module_port'])
        if self.warning_light is None:
            QMessageBox.warning(self, "OK", "Í≤ΩÍ¥ëÎì± Ìè¨Ìä∏Î•º ÌôïÏù∏ Ìï¥ Ï£ºÏÑ∏Ïöî.")
        
        self.alarm_btn.clicked.connect(self.pause_alarm) # ÎùºÏ¶àÎ≤†Î¶¨ÌååÏù¥ Í≤ΩÍ¥ëÎì± Ï¢ÖÎ£å
        self.alarm_test_btn.clicked.connect(self.test_alarm)

        if self.api_token and self.chat_id:
            self.messenger.set_telegram(self.api_token, self.chat_id)
            
        self.active_radio_btn.clicked.connect(self.telegram_active)
        self.unactive_radio_btn.clicked.connect(self.telegram_unactive)
        
        self.sk_active_radio_btn.clicked.connect(self.skelton_active)
        self.sk_unactive_radio_btn.clicked.connect(self.skelton_unactive)

        self.camera_add_btn.clicked.connect(self.add_camera)
        self.camera_data = self.json_data['camera_list']
        
        self.telegram_test_btn.clicked.connect(self.test_telegram)
        
        self.ai_conf = self.json_data['ai_model_conf']
        self.tr_th = self.json_data['tracking_th']
        
        self.scroll_content = QWidget()
        self.grid_layout = QGridLayout(self.scroll_content)
        self.scroll_area.setWidget(self.scroll_content)
        
        self.current_row = 0
        self.current_col = 0
        self.max_cols = 3
        
        self.relay_module_port_num = self.json_data['relay_module_port']

        self.selected_camera = None
        
        self.init_camera_list()
        self.check_telegram_info()
    
    def test_alarm(self):
        self.warning_light.on(auto_off_seconds=5)
        QMessageBox.information(self, "Í≤ΩÎ≥¥ ÌÖåÏä§Ìä∏", "Í≤ΩÎ≥¥ Ïã§Ìñâ ÏôÑÎ£å")

    def pause_alarm(self):
        self.warning_light.off()
        QMessageBox.information(self, "Í≤ΩÎ≥¥", "Í≤ΩÎ≥¥ Ï¢ÖÎ£å")
        
    def test_telegram(self):
        self.messenger.test_telegram_msg()
        
    def check_telegram_info(self):
        if self.api_token and self.chat_id:
            self.telegram_active()
        else:
            self.telegram_unactive()
            
    def update_json_value(self):
        self.json_data = self.setting.load_json()
        
    def open_camera_preview(self, camera_name):
        """Open a new window to display the camera preview."""
        if camera_name not in self.video_labels or camera_name not in self.camera_threads:
            QMessageBox.warning(self, "Ïò§Î•ò", f"Ïπ¥Î©îÎùº '{camera_name}'Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
            return

        # Ïù¥ÎØ∏ Ï°¥Ïû¨ÌïòÎäî Í≤ΩÏö∞ ÏÉàÎ°ú ÎßåÎì§ÏßÄ ÏïäÏùå
        if not hasattr(self, 'camera_preview_windows'):
            self.camera_preview_windows = {}

        if camera_name not in self.camera_preview_windows:
            preview_window = CameraPreview(camera_name)
            self.camera_preview_windows[camera_name] = preview_window
            
            # ÌôïÎåÄ Ï∞Ω Îã´Ìûê Îïå Ï≤òÎ¶¨ Ïó∞Í≤∞
            preview_window.closed.connect(self.restore_camera_signal)
            
            preview_window.show()
    
        # Ïó∞Í≤∞ Ïû¨ÏÑ§Ï†ï
        camera_thread = self.camera_threads[camera_name]
        camera_thread.frame_signal.disconnect()  # Í∏∞Ï°¥ Ïó∞Í≤∞ Ìï¥Ï†ú
        camera_thread.frame_signal.connect(
            lambda pixmap, available, name=camera_name: self.update_preview(name, pixmap)
        )

    def restore_camera_signal(self, camera_name):
        """Restore the camera signal to the original QLabel."""
        if camera_name not in self.camera_threads or camera_name not in self.video_labels:
            return

        camera_thread = self.camera_threads[camera_name]

        # ÌôïÎåÄ Ï∞Ω Ï†úÍ±∞
        if hasattr(self, 'camera_preview_windows') and camera_name in self.camera_preview_windows:
            del self.camera_preview_windows[camera_name]

        # Ïã†Ìò∏ Î≥µÏõê
        camera_thread.frame_signal.disconnect()
        camera_thread.frame_signal.connect(
            lambda pixmap, available, name=camera_name: self.update_frame(name, pixmap, available)
        )
        print(f"Camera signal restored to QLabel for '{camera_name}'.")
        
    def update_preview(self, camera_name, pixmap):
        if hasattr(self, 'camera_preview_windows') and camera_name in self.camera_preview_windows:
            self.camera_preview_windows[camera_name].update_frame(pixmap)
    
    def init_camera_list(self):
        camera_list_dict = self.json_data['camera_list']
        if len(camera_list_dict) >= 1:
            for camera_name, port in camera_list_dict.items():
                video_label = QLabel(f"{camera_name} - {port}")
                video_label.setFixedSize(400, 300)
                video_label.setAlignment(Qt.AlignCenter)
                video_label.setStyleSheet("border: 1px solid black; background-color: #000; color: white;")
                video_label.setContextMenuPolicy(Qt.CustomContextMenu)
                
                # Î†àÏù¥Î∏îÏóê Ïù¥Î¶Ñ Ï†ÄÏû•
                video_label.camera_name = camera_name
                
                # Ïó∞Í≤∞
                video_label.mouseDoubleClickEvent = partial(self.handle_double_click, camera_name)
                video_label.customContextMenuRequested.connect(
                    partial(self.handle_right_click, video_label)
                )
                self.video_labels[camera_name] = video_label

                # Grid LayoutÏóê Î†àÏù¥Î∏î Ï∂îÍ∞Ä
                self.grid_layout.addWidget(video_label, self.current_row, self.current_col)

                # Îã§Ïùå Ïó¥/Ìñâ Í≥ÑÏÇ∞
                self.current_col += 1
                if self.current_col >= self.max_cols:
                    self.current_col = 0
                    self.current_row += 1

                # Ïπ¥Î©îÎùº Ïä§Î†àÎìú ÏÉùÏÑ± Î∞è ÏãúÏûë
                camera_thread = CameraThread(port, self.ai_conf, self.tr_th, self.messenger)
                camera_thread.frame_signal.connect(lambda pixmap, available, name=camera_name: self.update_frame(name, pixmap, available))
                self.camera_threads[camera_name] = camera_thread
                camera_thread.start()
                print(f"Added and started camera: {camera_name} with port {port}")
    
        else:
            print(f"No data")
            
    def handle_double_click(self, camera_name, event):
        """Handle double-click on a QLabel to open the camera preview."""
        self.open_camera_preview(camera_name)
        
    def add_camera(self):
        """Ïπ¥Î©îÎùº Ï∂îÍ∞Ä"""
        camera_name, ok = QInputDialog.getText(self, "Ïπ¥Î©îÎùº Ï∂îÍ∞Ä", "Ïπ¥Î©îÎùº Ïù¥Î¶ÑÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî:")
        if not ok or not camera_name.strip():
            return
        
        if camera_name in self.video_labels:
            QMessageBox.warning(self, "Ïò§Î•ò", "Ïù¥ÎØ∏ Ï°¥Ïû¨ÌïòÎäî Ïπ¥Î©îÎùº Ïù¥Î¶ÑÏûÖÎãàÎã§.")
            return
        
        # Ïπ¥Î©îÎùº Ìè¨Ìä∏ Î≤àÌò∏ ÏûÖÎ†• Î∞õÍ∏∞
        port, ok = QInputDialog.getText(self, "Ìè¨Ìä∏ ÏÑ§Ï†ï", "Ïπ¥Î©îÎùº Ï£ºÏÜåÎ•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî:")
        if not ok:
            return
            
        try:
            # ÏÉàÎ°úÏö¥ Ïπ¥Î©îÎùº Ïä§Î†àÎìú ÏÉùÏÑ±
            camera_thread = CameraThread(port, self.ai_conf, self.tr_th, self.messenger)
            if camera_thread.model is None or camera_thread.model.model is None:
                QMessageBox.warning(self, "Ïò§Î•ò", "AI Î™®Îç∏ÏùÑ Î°úÎìúÌï† Ïàò ÏóÜÏäµÎãàÎã§. Î™®Îç∏ ÌååÏùºÏùÑ ÌôïÏù∏ÌïòÏÑ∏Ïöî.")
                return

            camera_thread.frame_signal.connect(
                lambda pixmap, available, name=camera_name: self.update_frame(name, pixmap, available)
            )
            
            # UI Î†àÏù¥Î∏î ÏÉùÏÑ±
            video_label = QLabel()
            video_label.setFixedSize(400, 300)
            video_label.setAlignment(Qt.AlignCenter)
            video_label.setText("Ïπ¥Î©îÎùº Ïó∞Í≤∞ÏùÑ ÌôïÏù∏Ìï¥ Ï£ºÏÑ∏Ïöî")
            video_label.setStyleSheet("border: 1px solid black; background-color: #000; color: white;")
            video_label.mousePressEvent = lambda event: self.handle_right_click(video_label) if event.button() == Qt.RightButton else None
            video_label.mouseDoubleClickEvent = lambda event: self.open_camera_preview(camera_name)
            video_label.camera_name = camera_name
            
            # Í∑∏Î¶¨ÎìúÏóê Î†àÏù¥Î∏î Ï∂îÍ∞Ä
            self.grid_layout.addWidget(video_label, self.current_row, self.current_col)
            
            # Îã§Ïùå ÏúÑÏπò Í≥ÑÏÇ∞
            self.current_col += 1
            if self.current_col >= self.max_cols:
                self.current_col = 0
                self.current_row += 1
            
            # Ïπ¥Î©îÎùº Ï†ïÎ≥¥ Ï†ÄÏû•
            self.video_labels[camera_name] = video_label
            self.camera_threads[camera_name] = camera_thread
            
            # JSON ÌååÏùºÏóê Ïπ¥Î©îÎùº Ï†ïÎ≥¥ Ï†ÄÏû•
            self.setting.add_dict_json('camera_list', camera_name, port)
            
            # Ïπ¥Î©îÎùº Ïä§Î†àÎìú ÏãúÏûë
            camera_thread.start()
            
        except Exception as e:
            QMessageBox.warning(self, "Ïò§Î•ò", f"Ïπ¥Î©îÎùº Ï∂îÍ∞Ä Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}")
            if camera_name in self.video_labels:
                self.video_labels[camera_name].deleteLater()
                del self.video_labels[camera_name]
            if camera_name in self.camera_threads:
                self.camera_threads[camera_name].stop()
                del self.camera_threads[camera_name]
    
    def handle_right_click(self, widget):
        """Ïö∞ÌÅ¥Î¶≠ Ïù¥Î≤§Ìä∏ Ï≤òÎ¶¨"""
        for name, label in self.video_labels.items():
            if label == widget:
                self.selected_camera = name
                context_menu = QMenu(self)
                rename_action = context_menu.addAction("Ïù¥Î¶Ñ Î≥ÄÍ≤Ω")
                port_change_action = context_menu.addAction("Ìè¨Ìä∏ Î≥ÄÍ≤Ω")
                delete_action = context_menu.addAction("ÏÇ≠Ï†ú")

                # Connect actions to their respective methods
                rename_action.triggered.connect(self.rename_camera)
                port_change_action.triggered.connect(self.change_camera_port)
                delete_action.triggered.connect(self.delete_camera)

                # Show context menu at the cursor's position
                context_menu.exec_(QCursor.pos())
                break
    
    def rename_camera(self):
        """Ïπ¥Î©îÎùº Ïù¥Î¶Ñ Î≥ÄÍ≤Ω"""
        if not self.selected_camera or self.selected_camera not in self.video_labels:
            return

        new_name, ok = QInputDialog.getText(self, "Ïù¥Î¶Ñ Î≥ÄÍ≤Ω", "ÏÉàÎ°úÏö¥ Ïù¥Î¶ÑÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî:", text=self.selected_camera)
        if ok and new_name.strip():
            if new_name in self.video_labels:
                QMessageBox.warning(self, "Ïò§Î•ò", "Ï§ëÎ≥µÎêú Ïù¥Î¶ÑÏûÖÎãàÎã§. Îã§Î•∏ Ïù¥Î¶ÑÏùÑ ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî.")
                return

            # Í∏∞Ï°¥ Ï†ïÎ≥¥ Í∞ÄÏ†∏Ïò§Í∏∞
            video_label = self.video_labels.pop(self.selected_camera)
            camera_thread = self.camera_threads.pop(self.selected_camera)

            # UI Î∞è ÏÜçÏÑ± ÏóÖÎç∞Ïù¥Ìä∏
            video_label.setText(f"{new_name} - {camera_thread.port}")
            video_label.camera_name = new_name  # ÏÉàÎ°úÏö¥ Ïù¥Î¶ÑÏúºÎ°ú Î†àÏù¥Î∏î ÏÜçÏÑ± ÏóÖÎç∞Ïù¥Ìä∏

            # ÎçîÎ∏î ÌÅ¥Î¶≠ Ïù¥Î≤§Ìä∏ Ìï∏Îì§Îü¨ Ïû¨ÏÑ§Ï†ï
            video_label.mouseDoubleClickEvent = lambda event: self.open_camera_preview(new_name)

            # ÏÉàÎ°úÏö¥ Ïù¥Î¶ÑÏúºÎ°ú Îß§Ìïë ÏóÖÎç∞Ïù¥Ìä∏
            self.video_labels[new_name] = video_label
            self.camera_threads[new_name] = camera_thread

            # JSON ÌååÏùº ÏóÖÎç∞Ïù¥Ìä∏
            self.setting.revise_key_dict_json('camera_list', self.selected_camera, new_name)

            # ÌôïÎåÄ Ï∞Ω Îß§Ìïë Í∞±Ïã†
            if hasattr(self, 'camera_preview_windows') and self.selected_camera in self.camera_preview_windows:
                preview_window = self.camera_preview_windows.pop(self.selected_camera)
                preview_window.setWindowTitle(f"{new_name} - ÌôïÎåÄ Î≥¥Í∏∞")
                self.camera_preview_windows[new_name] = preview_window

            # Í∏∞Ï°¥ ÏãúÍ∑∏ÎÑê Ïó∞Í≤∞ Ìï¥Ï†ú Î∞è Ïû¨Ïó∞Í≤∞
            camera_thread.frame_signal.disconnect()
            camera_thread.frame_signal.connect(lambda pixmap, available, name=new_name: self.update_frame(name, pixmap, available))

            print(f"Ïπ¥Î©îÎùº Ïù¥Î¶Ñ Î≥ÄÍ≤Ω: {self.selected_camera} -> {new_name}")
            self.selected_camera = new_name
   
    def change_camera_port(self):
        """Ïπ¥Î©îÎùº Ìè¨Ìä∏ Î≥ÄÍ≤Ω"""
        if not self.selected_camera or self.selected_camera not in self.camera_threads:
            return

        new_port, ok = QInputDialog.getText(self, "Ïπ¥Î©îÎùº Ï£ºÏÜå Î≥ÄÍ≤Ω", "ÏÉàÎ°úÏö¥ Ïπ¥Î©îÎùº Ï£ºÏÜåÎ•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî:")
        if ok:
            camera_thread = self.camera_threads[self.selected_camera]
            camera_thread.stop()  # Í∏∞Ï°¥ Ïä§Î†àÎìú Ï¢ÖÎ£å
            new_thread = CameraThread(new_port, self.ai_conf, self.tr_th, self.messenger)
            new_thread.frame_signal.connect(lambda pixmap, available, name=self.selected_camera: self.update_frame(name, pixmap, available))
            self.camera_threads[self.selected_camera] = new_thread
            new_thread.start()
            
            # Í∏∞Ï°¥ json ÌååÏùº Îß§Ìïë ÏóÖÎç∞Ïù¥Ìä∏
            self.setting.revise_val_dict_json('camera_list', self.selected_camera, new_port)
            
            # UI ÏóÖÎç∞Ïù¥Ìä∏
            video_label = self.video_labels[self.selected_camera]
            video_label.setText(f"{self.selected_camera} - {new_port}")

            # ÌôïÎåÄ Ï∞Ω Ïó∞Í≤∞ Ïû¨ÏÑ§Ï†ï
            if hasattr(self, 'camera_preview_windows') and self.selected_camera in self.camera_preview_windows:
                camera_thread.frame_signal.disconnect()  # Í∏∞Ï°¥ Ïó∞Í≤∞ Ìï¥Ï†ú
                new_thread.frame_signal.connect(
                    lambda pixmap, available, name=self.selected_camera: self.update_preview(name, pixmap)
                )

            print(f"Ïπ¥Î©îÎùº Ìè¨Ìä∏ Î≥ÄÍ≤Ω: {self.selected_camera} -> {new_port}")
            self.selected_camera = None
            
    def delete_camera(self):
        """Ïπ¥Î©îÎùº ÏÇ≠Ï†ú"""
        if not self.selected_camera or self.selected_camera not in self.camera_threads:
            QMessageBox.warning(self, "Ïò§Î•ò", "ÏÇ≠Ï†úÌï† Ïπ¥Î©îÎùºÎ•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî.")
            return

        # ÏÇ¨Ïö©Ïûê ÌôïÏù∏
        reply = QMessageBox.question(
            self,
            "ÏÇ≠Ï†ú ÌôïÏù∏",
            f"'{self.selected_camera}' Ïπ¥Î©îÎùºÎ•º ÏÇ≠Ï†úÌïòÏãúÍ≤†ÏäµÎãàÍπå?",
            QMessageBox.Yes | QMessageBox.No,
            QMessageBox.No,
        )

        if reply != QMessageBox.Yes:
            return

        # Ïä§Î†àÎìú Ï†ïÎ¶¨
        camera_thread = self.camera_threads[self.selected_camera]
        camera_thread.frame_signal.disconnect()  # ÏãúÍ∑∏ÎÑê Ïó∞Í≤∞ Ìï¥Ï†ú
        camera_thread.stop()
        del self.camera_threads[self.selected_camera]

        # UI ÏöîÏÜå ÏÇ≠Ï†ú
        video_label = self.video_labels[self.selected_camera]
        self.grid_layout.removeWidget(video_label)
        video_label.deleteLater()
        del self.video_labels[self.selected_camera]

        # json ÏöîÏÜå ÏÇ≠Ï†ú
        self.setting.remove_dict_json(self.selected_camera)
        
        # Î†àÏù¥ÏïÑÏõÉ Ï†ïÎ¶¨
        self.rearrange_grid_layout()

        print(f"Ïπ¥Î©îÎùº ÏÇ≠Ï†ú ÏôÑÎ£å: {self.selected_camera}")
        self.selected_camera = None
    
    def rearrange_grid_layout(self):
        row, col = 0, 0
        widgets = []

        # ÌòÑÏû¨ GridLayoutÏóê ÏûàÎäî Î™®Îì† ÏúÑÏ†Ø ÏàòÏßë
        for i in range(self.grid_layout.count()):
            widget = self.grid_layout.itemAt(i).widget()
            if isinstance(widget, QLabel):
                widgets.append(widget)

        # Î™®Îì† ÏúÑÏ†Ø Ï†úÍ±∞
        for i in reversed(range(self.grid_layout.count())):
            self.grid_layout.itemAt(i).widget().setParent(None)

        # ÏúÑÏ†ØÎì§ÏùÑ Ìïú Ïπ∏Ïî© ÎãπÍ≤® Ïû¨Î∞∞Ïπò
        for widget in widgets:
            self.grid_layout.addWidget(widget, row, col)
            col += 1
            if col >= self.max_cols:
                col = 0
                row += 1

        # ÌòÑÏû¨ ÏúÑÏπò ÏóÖÎç∞Ïù¥Ìä∏
        self.current_row = row
        self.current_col = col
                        
    def show_error(self, error_message):
        """Show error messages."""
        QMessageBox.warning(self, "Ïò§Î•ò", error_message)

    def set_cursor(self):
        cusor_path = resource_path('style/cursor/jyy.png')
        cursor_pixmap = QPixmap(cusor_path)
        scaled_pixmap = cursor_pixmap.scaled(48, 48, Qt.KeepAspectRatio, Qt.SmoothTransformation)
        custom_cursor = QCursor(scaled_pixmap, 10, 10)
        self.setCursor(custom_cursor)
        
    def load_external_font(self, font_path):
        font_id = QFontDatabase.addApplicationFont(font_path)
        if font_id == -1:
            print(f"Ìè∞Ìä∏Î•º Î°úÎìúÌïòÏßÄ Î™ªÌñàÏäµÎãàÎã§: {font_path}")
            return ""
        font_families = QFontDatabase.applicationFontFamilies(font_id)
        if font_families:
            return font_families[0]
        else:
            print("Îì±Î°ùÎêú Ìè∞Ìä∏ Ïù¥Î¶ÑÏùÑ Í∞ÄÏ†∏Ïò§ÏßÄ Î™ªÌñàÏäµÎãàÎã§.")
            return ""

    def load_stylesheet(self):
        # stylesheet.qss ÌååÏùº Î°úÎìú
        self.setStyleSheet("")
        qss_file_path = resource_path('style/stylesheet.qss')
        qss_file = QFile(qss_file_path)
        qss_file.open(QFile.ReadOnly | QFile.Text)
        qss_stream = QTextStream(qss_file)
        qss_stream_all = qss_stream.readAll()
        qss_file.close()
        
        font_path = resource_path("style/font/Maplestory Light.ttf")  # Ìè∞Ìä∏ ÌååÏùº Í≤ΩÎ°ú
        font_name = self.load_external_font(font_path)
        
        if font_name:
            # QSSÏóêÏÑú Ìè∞Ìä∏ Ïù¥Î¶Ñ ÎåÄÏ≤¥
            qss_stream_all = qss_stream_all.replace('Maple Story', font_name)

            # Í∏∞Ï°¥ Ïä§ÌÉÄÏùº Ï¥àÍ∏∞Ìôî ÌõÑ ÏÉà Ïä§ÌÉÄÏùº Ï†ÅÏö©
            self.setStyleSheet("")
            self.setStyleSheet(qss_stream_all)

            # ÌîÑÎ°úÍ∑∏Îû®Ï†ÅÏúºÎ°ú Ìè∞Ìä∏ ÏÑ§Ï†ï (ÌïÑÏöîÏãú)
            font = QFont(font_name)
            font.setPointSize(16)
            self.setFont(font)
        else:
            self.setStyleSheet(qss_stream_all)

    def skelton_active(self):
        for camera_thread in self.camera_threads.values():
            camera_thread.change_skeleton_visualize_func(flag=True)
    
    def skelton_unactive(self):
        for camera_thread in self.camera_threads.values():
            camera_thread.change_skeleton_visualize_func(flag=False)
        
    def telegram_active(self):
        if self.telegram_winodw_class.get_telegram_api_label() == "" or self.telegram_winodw_class.get_telegram_id_label() == "":
            QMessageBox.warning(self, "Ïò§Î•ò", "ÌÖîÎ†àÍ∑∏Îû® Ï†ïÎ≥¥Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
            self.unactive_radio_btn.setChecked(True)
        else:
            if len(self.video_labels) > 0:
                for camera_thread in self.camera_threads.values():
                    camera_thread.change_telegram_func(flag=True)
                self.active_radio_btn.setChecked(True)
        
    def telegram_unactive(self):
        for camera_thread in self.camera_threads.values():
            camera_thread.change_telegram_func(flag=False)
        
    def open_model_conf_dialog(self):
        self.model_window_class.open()
        self.ai_conf = self.model_window_class.get_ai_conf()
        self.tr_th = self.model_window_class.get_tracking_threshold()
        for camera_thread in self.camera_threads.values():
            camera_thread.model.change_value(self.ai_conf, self.tr_th)
            
    def open_telegram_info_dialog(self):
        self.telegram_winodw_class.open()
        self.api_token = self.telegram_winodw_class.get_telegram_api_label()
        self.chat_id = self.telegram_winodw_class.get_telegram_id_label()
        self.messenger.set_telegram(self.api_token, self.chat_id)
        self.check_telegram_info()
    
    def open_relay_port_dialog(self):
        self.relay_port_window_class.open()
        self.relay_module_port_num = self.relay_port_window_class.get_port_num()
        self.warning_light.change_port(self.relay_module_port_num)

    def update_frame(self, camera_name, pixmap, available):
        if camera_name not in self.video_labels:
            return  # Ïπ¥Î©îÎùºÍ∞Ä ÏÇ≠Ï†úÎêú Í≤ΩÏö∞ Ï≤òÎ¶¨ Ï§ëÎã®

        self.video_labels[camera_name].setPixmap(pixmap)
        if not available:
            self.video_labels[camera_name].setStyleSheet("border: 1px solid red; background-color: #000; color: white;")
        else:
            self.video_labels[camera_name].setStyleSheet("border: 1px solid black; background-color: #000; color: white;")
    
    def closeEvent(self, event):
        """Stop all camera threads when the application is closed."""
        for thread in self.camera_threads.values():
            thread.stop()
        super().closeEvent(event)

if __name__ == '__main__':
    app = QApplication(sys.argv)

    main_window = WindowClass()
    main_window.setWindowState(Qt.WindowMaximized)
    main_window.show()
    
    app.exec_()